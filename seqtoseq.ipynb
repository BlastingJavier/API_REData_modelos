{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "f56191c7ce0b73b3466ae7dded3423d6980e340342c7b9ccfd9058e348dc3979"
   }
  },
  "interpreter": {
   "hash": "f56191c7ce0b73b3466ae7dded3423d6980e340342c7b9ccfd9058e348dc3979"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras as tfk\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, LayerNormalization, RepeatVector\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "\n",
    "from utils import preprocess_time_series_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('REE_2016_2020_gluonTS.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                      Date  value\n",
      "0      2016-01-02 23:00:00  24151\n",
      "1      2016-01-03 00:00:00  22170\n",
      "2      2016-01-03 01:00:00  20691\n",
      "3      2016-01-03 02:00:00  19737\n",
      "4      2016-01-03 03:00:00  19437\n",
      "...                    ...    ...\n",
      "34940  2019-12-28 19:00:00  29282\n",
      "34941  2019-12-28 20:00:00  29266\n",
      "34942  2019-12-28 21:00:00  28022\n",
      "34943  2019-12-28 22:00:00  25964\n",
      "34944  2019-12-28 23:00:00  24680\n",
      "\n",
      "[34945 rows x 2 columns]\n",
      "(17497, 1)\n",
      "(8760, 1)\n",
      "(8688, 1)\n",
      "shape train/val (17497, 1) (8760, 1) (8688, 1)\n",
      "Tamano de la serie temporal 2\n",
      "Tamano de la serie temporal 2\n",
      "Tamano de la serie temporal 2\n",
      "shape train/val (17396, 96, 1, 1) (8659, 96, 1, 1) (8587, 96, 1, 1)\n",
      "(17396, 96, 1, 1)\n",
      "/home/blasting/TFG_TimeSeries/notebooks/utils.py:133: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  val_data = df[date_val].to_numpy()\n",
      "/home/blasting/TFG_TimeSeries/notebooks/utils.py:134: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  test_data = df[date_test].to_numpy()\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('REE_2016_2020_gluonTS.csv')\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, scaler = preprocess_time_series_v2(df, date_init='2016', date_final='2017', date_val='2018', date_test='2019', \n",
    "                            past_timestamps=96, forecasting_horizon=6, \n",
    "                            standarize=True, metafeatures=False, tendency=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 6, 80), dtype=tf.float32, name=None), name='lstm_1/transpose_1:0', description=\"created by layer 'lstm_1'\")\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 96, 1)]      0                                            \n__________________________________________________________________________________________________\nlstm (LSTM)                     [(None, 80), (None,  26240       input_1[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 80)           320         lstm[0][0]                       \n__________________________________________________________________________________________________\nrepeat_vector (RepeatVector)    (None, 6, 80)        0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 80)           320         lstm[0][2]                       \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   (None, 6, 80)        51520       repeat_vector[0][0]              \n                                                                 batch_normalization[0][0]        \n                                                                 batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\ntime_distributed (TimeDistribut (None, 6, 1)         81          lstm_1[0][0]                     \n==================================================================================================\nTotal params: 78,481\nTrainable params: 78,161\nNon-trainable params: 320\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_train = tfk.layers.Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "encoder_last_h1, encoder_last_h2, encoder_last_c = LSTM(\n",
    " 80, dropout=0.1, recurrent_dropout=0.1, \n",
    " return_sequences=False, return_state=True)(input_train)\n",
    "encoder_last_h1 = tfk.layers.BatchNormalization(momentum=0.6)(encoder_last_h1)\n",
    "encoder_last_c = tfk.layers.BatchNormalization(momentum=0.6)(encoder_last_c)\n",
    "\n",
    "decoder = RepeatVector(y_train.shape[1])(encoder_last_h1)\n",
    "decoder = LSTM(80, dropout=0.1, recurrent_dropout=0.1, return_state=False, return_sequences=True)(\n",
    "    decoder, initial_state=[encoder_last_h1, encoder_last_c])\n",
    "print(decoder)\n",
    "\n",
    "outputs = TimeDistributed(Dense(1))(decoder)\n",
    "\n",
    "model = tfk.Model(inputs=input_train, outputs=outputs)\n",
    "model.compile(loss=tfk.losses.MeanSquaredError(), optimizer= tfk.optimizers.Adam(),\n",
    "metrics=[tfk.metrics.MeanAbsoluteError()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "68/68 [==============================] - 26s 387ms/step - loss: 0.0316 - mean_absolute_error: 0.1255 - val_loss: 0.0256 - val_mean_absolute_error: 0.1062\n",
      "Epoch 2/10\n",
      "68/68 [==============================] - 23s 334ms/step - loss: 0.0330 - mean_absolute_error: 0.1286 - val_loss: 0.0277 - val_mean_absolute_error: 0.1143\n",
      "Epoch 3/10\n",
      "68/68 [==============================] - 23s 332ms/step - loss: 0.0327 - mean_absolute_error: 0.1278 - val_loss: 0.0229 - val_mean_absolute_error: 0.1022\n",
      "Epoch 4/10\n",
      "68/68 [==============================] - 20s 296ms/step - loss: 0.0313 - mean_absolute_error: 0.1262 - val_loss: 0.0267 - val_mean_absolute_error: 0.1085\n",
      "Epoch 5/10\n",
      "68/68 [==============================] - 22s 317ms/step - loss: 0.0323 - mean_absolute_error: 0.1278 - val_loss: 0.0260 - val_mean_absolute_error: 0.1101\n",
      "Epoch 6/10\n",
      "68/68 [==============================] - 21s 313ms/step - loss: 0.0314 - mean_absolute_error: 0.1264 - val_loss: 0.0239 - val_mean_absolute_error: 0.1016\n",
      "Epoch 7/10\n",
      "68/68 [==============================] - 24s 359ms/step - loss: 0.0305 - mean_absolute_error: 0.1239 - val_loss: 0.0238 - val_mean_absolute_error: 0.1041\n",
      "Epoch 8/10\n",
      "68/68 [==============================] - 22s 324ms/step - loss: 0.0305 - mean_absolute_error: 0.1243 - val_loss: 0.0264 - val_mean_absolute_error: 0.1096\n",
      "Epoch 9/10\n",
      "68/68 [==============================] - 22s 329ms/step - loss: 0.0314 - mean_absolute_error: 0.1262 - val_loss: 0.0253 - val_mean_absolute_error: 0.1054\n",
      "Epoch 10/10\n",
      "68/68 [==============================] - 24s 354ms/step - loss: 0.0290 - mean_absolute_error: 0.1215 - val_loss: 0.0251 - val_mean_absolute_error: 0.1028\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=10, \n",
    "                    validation_data=(X_val, y_val)) \n",
    "\n",
    "\n",
    "loss = history.history['loss']            #entrenamiento\n",
    "val_loss = history.history['val_loss']    #validacion\n",
    "#val_mse = history.history['val_mse']    #validacion\n",
    "#mse = history.history['mse']    #validacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(yhat, y, scaler):\n",
    "\treturn scaler.inverse_transform(y),  scaler.inverse_transform(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "y_hat_2 = model.predict(X_val)\n",
    "\n",
    "y_test2, y_hat = inverse_transform(y_hat, y_test, scaler)\n",
    "y_val2, y_hat_2 = inverse_transform(y_hat_2, y_val, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "def evaluate_forecasts(test, forecasts, n_seq):\n",
    "\tfor i in range(n_seq):\n",
    "\t\tactual = [row[i] for row in test]\n",
    "\t\tpredicted = [forecast[i] for forecast in forecasts]\n",
    "\t\trmse = mean_absolute_error(actual, predicted)\n",
    "\t\tprint('t+%d MSE: %f' % ((i+1), rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test\nt+1 MSE: 339.420176\nt+2 MSE: 412.268886\nt+3 MSE: 474.754075\nt+4 MSE: 528.673938\nt+5 MSE: 566.340296\nt+6 MSE: 593.365637\nvalidacion\nt+1 MSE: 318.964585\nt+2 MSE: 392.016248\nt+3 MSE: 454.373082\nt+4 MSE: 507.370392\nt+5 MSE: 540.634629\nt+6 MSE: 556.963158\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")\n",
    "evaluate_forecasts(y_test2, y_hat, 6)\n",
    "\n",
    "print(\"validacion\")\n",
    "evaluate_forecasts(y_val2, y_hat_2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "461.720349"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "(318.964585 + 392.016248 + 454.373082 + 507.370392 + 540.634629 + 556.963158)/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}