{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "f56191c7ce0b73b3466ae7dded3423d6980e340342c7b9ccfd9058e348dc3979"
   }
  },
  "interpreter": {
   "hash": "f56191c7ce0b73b3466ae7dded3423d6980e340342c7b9ccfd9058e348dc3979"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras as tfk\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, LayerNormalization, RepeatVector\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "\n",
    "from utils import preprocess_time_series_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('REE_2016_2020_gluonTS.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                      Date  value\n",
      "0      2016-01-02 23:00:00  24151\n",
      "1      2016-01-03 00:00:00  22170\n",
      "2      2016-01-03 01:00:00  20691\n",
      "3      2016-01-03 02:00:00  19737\n",
      "4      2016-01-03 03:00:00  19437\n",
      "...                    ...    ...\n",
      "34940  2019-12-28 19:00:00  29282\n",
      "34941  2019-12-28 20:00:00  29266\n",
      "34942  2019-12-28 21:00:00  28022\n",
      "34943  2019-12-28 22:00:00  25964\n",
      "34944  2019-12-28 23:00:00  24680\n",
      "\n",
      "[34945 rows x 2 columns]\n",
      "(17497, 1)\n",
      "(8760, 1)\n",
      "(8688, 1)\n",
      "shape train/val (17497, 1) (8760, 1) (8688, 1)\n",
      "Tamano de la serie temporal 2\n",
      "Tamano de la serie temporal 2\n",
      "/home/blasting/TFG_TimeSeries/notebooks/utils.py:133: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  val_data = df[date_val].to_numpy()\n",
      "/home/blasting/TFG_TimeSeries/notebooks/utils.py:134: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  test_data = df[date_test].to_numpy()\n",
      "Tamano de la serie temporal 2\n",
      "shape train/val (17396, 96, 1, 1) (8659, 96, 1, 1) (8587, 96, 1, 1)\n",
      "(17396, 96, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('REE_2016_2020_gluonTS.csv')\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, scaler = preprocess_time_series_v2(df, date_init='2016', date_final='2017', date_val='2018', date_test='2019', \n",
    "                            past_timestamps=96, forecasting_horizon=6, \n",
    "                            standarize=True, metafeatures=False, tendency=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 6, 100), dtype=tf.float32, name=None), name='lstm_11/transpose_1:0', description=\"created by layer 'lstm_11'\")\n<bound method Model.summary of <tensorflow.python.keras.engine.functional.Functional object at 0x7fbd35ed2c90>>\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_6 (InputLayer)            [(None, 96, 1)]      0                                            \n__________________________________________________________________________________________________\nlstm_10 (LSTM)                  [(None, 96, 100), (N 40800       input_6[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 100)          400         lstm_10[0][1]                    \n__________________________________________________________________________________________________\nrepeat_vector_5 (RepeatVector)  (None, 6, 100)       0           batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 100)          400         lstm_10[0][2]                    \n__________________________________________________________________________________________________\nlstm_11 (LSTM)                  (None, 6, 100)       80400       repeat_vector_5[0][0]            \n                                                                 batch_normalization_11[0][0]     \n                                                                 batch_normalization_12[0][0]     \n__________________________________________________________________________________________________\ndot_9 (Dot)                     (None, 6, 96)        0           lstm_11[0][0]                    \n                                                                 lstm_10[0][0]                    \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 6, 96)        0           dot_9[0][0]                      \n__________________________________________________________________________________________________\ndot_10 (Dot)                    (None, 6, 100)       0           activation_4[0][0]               \n                                                                 lstm_10[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 6, 100)       400         dot_10[0][0]                     \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 6, 200)       0           batch_normalization_13[0][0]     \n                                                                 lstm_11[0][0]                    \n__________________________________________________________________________________________________\ntime_distributed_1 (TimeDistrib (None, 6, 1)         201         concatenate_1[0][0]              \n==================================================================================================\nTotal params: 122,601\nTrainable params: 122,001\nNon-trainable params: 600\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_train = tfk.layers.Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "encoder_stack_h, encoder_last_h, encoder_last_c = LSTM(\n",
    " 100, dropout=0.1, recurrent_dropout=0.1, \n",
    " return_sequences=True, return_state=True)(input_train)\n",
    "encoder_last_h = tfk.layers.BatchNormalization(momentum=0.6)(encoder_last_h)\n",
    "encoder_last_c = tfk.layers.BatchNormalization(momentum=0.6)(encoder_last_c)\n",
    "\n",
    "decoder_input = RepeatVector(y_train.shape[1])(encoder_last_h)\n",
    "decoder_stack_h = LSTM(100, dropout=0.1, recurrent_dropout=0.1, return_state=False, return_sequences=True)(\n",
    "    decoder_input, initial_state=[encoder_last_h, encoder_last_c])\n",
    "print(decoder_stack_h)\n",
    "attention = dot([decoder_stack_h, encoder_stack_h], axes=[2, 2])\n",
    "attention = Activation('softmax')(attention)\n",
    "#print(attention)\n",
    "context = dot([attention, encoder_stack_h], axes=[2,1])\n",
    "context = BatchNormalization(momentum=0.6)(context)\n",
    "#print(context)\n",
    "decoder_combined_context = concatenate([context, decoder_stack_h])\n",
    "#print(decoder_combined_context)\n",
    "\n",
    "outputs = TimeDistributed(Dense(1))(decoder_combined_context)\n",
    "model = tfk.Model(inputs=input_train, outputs=outputs)\n",
    "print(model.summary)\n",
    "\n",
    "model.compile(loss=tfk.losses.MeanSquaredError(), optimizer= tfk.optimizers.Adam(),\n",
    "metrics=[tfk.metrics.MeanAbsoluteError()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "68/68 [==============================] - 36s 529ms/step - loss: 0.0241 - mean_absolute_error: 0.1119 - val_loss: 0.0215 - val_mean_absolute_error: 0.1026\n",
      "Epoch 2/2\n",
      "68/68 [==============================] - 37s 538ms/step - loss: 0.0242 - mean_absolute_error: 0.1118 - val_loss: 0.0228 - val_mean_absolute_error: 0.0974\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=2, \n",
    "                    validation_data=(X_val, y_val)) \n",
    "\n",
    "\n",
    "loss = history.history['loss']            #entrenamiento\n",
    "val_loss = history.history['val_loss']    #validacion\n",
    "#val_mse = history.history['val_mse']    #validacion\n",
    "#mse = history.history['mse']    #validacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(yhat, y, scaler):\n",
    "\treturn scaler.inverse_transform(y),  scaler.inverse_transform(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "y_hat_2 = model.predict(X_val)\n",
    "\n",
    "y_test2, y_hat = inverse_transform(y_hat, y_test, scaler)\n",
    "y_val2, y_hat_2 = inverse_transform(y_hat_2, y_val, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "def evaluate_forecasts(test, forecasts, n_seq):\n",
    "\tfor i in range(n_seq):\n",
    "\t\tactual = [row[i] for row in test]\n",
    "\t\tpredicted = [forecast[i] for forecast in forecasts]\n",
    "\t\trmse = mean_absolute_error(actual, predicted)\n",
    "\t\tprint('t+%d MSE: %f' % ((i+1), rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test\nt+1 MSE: 348.412469\nt+2 MSE: 390.778849\nt+3 MSE: 422.100241\nt+4 MSE: 458.014382\nt+5 MSE: 499.975009\nt+6 MSE: 541.338184\nvalidacion\nt+1 MSE: 342.744563\nt+2 MSE: 385.648673\nt+3 MSE: 415.607388\nt+4 MSE: 453.545182\nt+5 MSE: 495.023425\nt+6 MSE: 532.757518\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")\n",
    "evaluate_forecasts(y_test2, y_hat, 6)\n",
    "\n",
    "print(\"validacion\")\n",
    "evaluate_forecasts(y_val2, y_hat_2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "443.43652233333324"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "(348.412469 + 390.778849 + 422.100241 + 458.014382 + 499.975009 + 541.338184)/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}